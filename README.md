# ByteMeSumAI

![License](https://img.shields.io/badge/license-MIT-blue)
![Python](https://img.shields.io/badge/python-3.8%2B-blue)
![Development Status](https://img.shields.io/badge/status-alpha-orange)

**Intelligent document processing with advanced chunking and summarization for the AI era.**

## ğŸš€ Overview

SumWiseAI tackles one of the most critical challenges in building effective AI solutions: **processing long, unstructured documents**. It's not just a summarization tool - it's an essential component in your RAG (Retrieval-Augmented Generation) pipeline that transforms how your AI systems handle complex documents.

**The hard truth**: Your AI solution is only as good as the data foundation it's built upon. Traditional document processing approaches break down when faced with lengthy, complex documents that span multiple topics, entities, and timelines.

SumWiseAI changes the game by implementing:

- **Boundary-Aware Chunking**: Intelligently splits documents at natural semantic boundaries, not arbitrary character counts
- **Multi-Strategy Summarization**: Applies different summarization approaches based on document complexity
- **Entity and Temporal Analysis**: Tracks key entities and chronological information across document sections
- **Hierarchical Processing**: Maintains context across document sections for coherent understanding

## ğŸ’¡ Why Your Data Strategy Matters

In the rush to deploy LLM solutions, many teams overlook a fundamental truth: **document processing is not a commodity**. The way you chunk, summarize, and represent documents directly impacts:

- Retrieval accuracy
- Context retention
- Hallucination reduction
- Computational efficiency
- User experience

SumWiseAI is built on the principle that **your data strategy is as important as your solution architecture**. It provides the tools to transform raw documents into structured, coherent, and contextually rich inputs for your AI systems.

## ğŸ” Key Features

- **Intelligent Chunking**:
  - Fixed-size chunking (baseline)
  - Boundary-aware chunking (detects natural boundaries)
  - Semantic chunking (preserves meaning)

- **Multi-Strategy Summarization**:
  - Basic summarization (concise, detailed, narrative)
  - Extractive summarization (key sentences)
  - Entity-focused summarization (key entities)
  - Temporal summarization (chronological information)

- **Advanced Processing**:
  - Hierarchical document handling
  - Entity tracking across document sections
  - Cross-reference preservation
  - Context window optimization

- **Practical Tools**:
  - Document loading utilities
  - Report generation
  - Evaluation metrics
  - Framework integration

## ğŸ—ï¸ Use Cases

### Enterprise Document Processing

Process long corporate documents like:
- Earnings call transcripts
- Annual reports
- Technical documentation
- Legal contracts

```python
from sumwiseai import Document, DocumentProcessor

# Load an earnings call transcript
doc = Document.from_file("q4_earnings_call.txt")

# Process with intelligent chunking and summarization
processor = DocumentProcessor()
results = processor.process_document(
    document=doc,
    chunking_strategy="boundary_aware",
    summarization_strategies=["basic", "entity_focused"]
)
```

### RAG Enhancement

Supercharge your RAG pipeline with advanced document handling:

```python
# Traditional RAG breaks context on long documents
# SumWiseAI preserves semantic structure
from sumwiseai import chunk, summarize

# Intelligent chunking that respects document structure
chunks = chunk(document, strategy="boundary_aware")

# Generate targeted summaries for each chunk
summaries = [summarize(chunk.text, strategy="entity_focused") for chunk in chunks]

# Use in your RAG pipeline
for chunk, summary in zip(chunks, summaries):
    knowledge_base.add(
        text=chunk.text,
        metadata={"summary": summary.summary, "entities": summary.metadata["entities"]}
    )
```

### Research and Analysis

Extract insights from complex academic or research documents:

```python
from sumwiseai import Document, process_document

# Load a complex research paper
paper = Document.from_file("research_paper.pdf")

# Process with focus on entities and temporal information
results = process_document(
    paper,
    chunking_strategy="semantic",
    summarization_strategies=["entity_focused", "temporal"]
)

# Extract key research entities
entities = results["summarization_result"]["entity_focused"]["entities"]
print(f"Key research entities: {entities}")
```

## ğŸ“Š The SumWiseAI Advantage

| Challenge | Traditional Approach | SumWiseAI Approach |
|-----------|----------------------|-------------------|
| Long documents | Fixed-size chunking breaks context | Boundary-aware chunking preserves semantic structure |
| Multiple topics | Context mixing across unrelated sections | Topic-aware processing maintains separation |
| Entity tracking | Entities fragmented across chunks | Entity-focused summarization tracks across document |
| Temporal sequences | Chronological information lost | Temporal summaries preserve time-based relationships |
| Structure preservation | Document structure ignored | Format-aware processing respects original structure |

## ğŸŒ± Getting Started



```
sumwiseai/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ sumwiseai/
â”‚       â”œâ”€â”€ __init__.py                 # Package initialization
â”‚       â”œâ”€â”€ llm/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ client.py               # Provider-agnostic LLM client
â”‚       â”‚   â””â”€â”€ providers/              # Provider implementations
â”‚       â”‚       â”œâ”€â”€ __init__.py
â”‚       â”‚       â””â”€â”€ base.py             # Base provider interface
â”‚       â”œâ”€â”€ chunking/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ processor.py            # Main chunking processor
â”‚       â”‚   â”œâ”€â”€ fixed.py                # Fixed-size chunking
â”‚       â”‚   â”œâ”€â”€ boundary.py             # Boundary-aware chunking
â”‚       â”‚   â”œâ”€â”€ semantic.py             # Semantic chunking
â”‚       â”‚   â””â”€â”€ models.py               # Chunk and Boundary models
â”‚       â”œâ”€â”€ summarization/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ processor.py            # Main summarization processor
â”‚       â”‚   â”œâ”€â”€ basic.py                # Basic summarization
â”‚       â”‚   â”œâ”€â”€ extractive.py           # Extractive summarization
â”‚       â”‚   â”œâ”€â”€ entity.py               # Entity-focused summarization
â”‚       â”‚   â”œâ”€â”€ temporal.py             # Temporal summarization
â”‚       â”‚   â””â”€â”€ models.py               # Summary result models
â”‚       â”œâ”€â”€ processing/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ document.py             # Document processor
â”‚       â”‚   â””â”€â”€ hierarchical.py         # Hierarchical processing
â”‚       â”œâ”€â”€ loaders/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ document.py             # Document loader
â”‚       â”œâ”€â”€ reporting/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ markdown.py             # Markdown reporter
â”‚       â”‚   â””â”€â”€ evaluation.py           # Evaluation utilities
â”‚       â”œâ”€â”€ utils/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ cache.py                # Caching utilities
â”‚       â”‚   â””â”€â”€ metrics.py              # Evaluation metrics
â”‚       â””â”€â”€ models/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â””â”€â”€ document.py             # Document model
â”œâ”€â”€ tests/                              # Test suite
â”‚   â”œâ”€â”€ unit/                           # Unit tests
â”‚   â”œâ”€â”€ integration/                    # Integration tests
â”‚   â””â”€â”€ fixtures/                       # Test fixtures
â”œâ”€â”€ examples/                           # Example scripts
â”‚   â”œâ”€â”€ basic_summarization.py
â”‚   â”œâ”€â”€ boundary_aware_chunking.py
â”‚   â””â”€â”€ notebooks/                      # Jupyter notebooks
â”œâ”€â”€ docs/                               # Documentation
â”œâ”€â”€ pyproject.toml                      # Package configuration
â”œâ”€â”€ LICENSE                             # License file
â””â”€â”€ README.md                           # This file
```


### Installation

```bash
pip install sumwiseai
```

### Quick Start

```python
from sumwiseai import summarize, chunk

# Simple document summarization
summary = summarize("This is a long document that contains important information...")
print(summary.summary)

# Intelligent chunking
chunks = chunk(long_document, strategy="boundary_aware")
print(f"Document divided into {len(chunks)} semantic chunks")
```

For detailed examples, check the [examples](./examples) directory.

## ğŸš§ Project Status

SumWiseAI is currently in **alpha stage**. While the core functionality is available and useful, we're actively enhancing the library based on real-world usage and feedback.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

<p align="center">
<strong>Your AI is only as good as the documents it processes.</strong><br>
Make document processing a strategic advantage with SumWiseAI.
</p>

